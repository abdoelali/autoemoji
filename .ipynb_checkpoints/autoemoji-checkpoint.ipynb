{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import wget\n",
    "import zipfile\n",
    "import gspread\n",
    "import matplotlib.pyplot as plt\n",
    "from oauth2client.service_account import ServiceAccountCredentials\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, accuracy_score\n",
    "from skimage import color, exposure, feature, io, transform\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "# from matplotlib import pyplot as plt\n",
    "\n",
    "# setup_run = True\n",
    "# data_base_path = 'https://ait.ethz.ch/public-data/computational_interaction2016/'\n",
    "\n",
    "# if not os.path.exists('train'):\n",
    "#     print('[INFO]: Looks like you do not have training data. Let me fetch that for you.')\n",
    "#     sys.stdout.flush()\n",
    "#     url_traindata = data_base_path+'train.zip'\n",
    "#     filename = wget.download(url_traindata)\n",
    "#     zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "#     zip_ref.extractall('./')\n",
    "#     zip_ref.close()\n",
    "#     print('[INFO]: Training data fetching completed.')\n",
    "#     sys.stdout.flush()\n",
    "    \n",
    "# if not os.path.exists('./test_T30_R60'):\n",
    "#     print('[INFO]: Looks like you do not have testing data. Let me fetch that for you')\n",
    "#     sys.stdout.flush()\n",
    "#     url_testdata = data_base_path+'test_T30_R60.zip'\n",
    "#     filename = wget.download(url_testdata)\n",
    "#     zip_ref = zipfile.ZipFile(filename, 'r')\n",
    "#     zip_ref.extractall('./')\n",
    "#     zip_ref.close()\n",
    "#     print('[INFO]: Testing data fetching completed.')\n",
    "#     sys.stdout.flush()\n",
    "    \n",
    "# Additionally, there's a second, more challenging dataset that you can download from \n",
    "# url_testdata_hard = 'https://ait.inf.ethz.ch/teaching/courses/2016-SS-User-Interface-Engineering/downloads/exercises/test_T30_R90.zip '\n",
    "    \n",
    "# Compute accuracy, precision, recall and confusion matrix and (optionally) prints them on screen\n",
    "def compute_scores(y_pred, y_true, verbose=False):\n",
    "\n",
    "    hits = 0\n",
    "    for p in range(1,len(y_true)):\n",
    "        if y_pred[p] == y_true[p]:\n",
    "            hits += 1\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='macro')\n",
    "    recall = recall_score(y_true, y_pred, average='macro')\n",
    "    conf_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    if(verbose):\n",
    "        print (\"(RW) Accuracy: \" + str(accuracy) + \"(\" + str(hits) + \"/\" + str(len(y_true)) + \")\")\n",
    "        print (\"Precision: \" + str(precision))\n",
    "        print (\"Recall: \" + str(recall))\n",
    "        print (\"Confusion Matrix\")\n",
    "        print (conf_mat)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    return accuracy, precision, recall\n",
    "\n",
    "\n",
    "# Extract HOG features from an image and (optionally) show the features superimposed on it \n",
    "def extractHOG(inputimg, showHOG=False): \n",
    "    \n",
    "    # convert image to single-channel, grayscale\n",
    "    image = color.rgb2gray(inputimg)\n",
    "\n",
    "    #extract HOG features\n",
    "    if showHOG:\n",
    "        fd, hog_image = feature.hog(image, orientations=36, \n",
    "                                    pixels_per_cell=(16, 16),\n",
    "                                    cells_per_block=(2, 2), \n",
    "                                    visualise=showHOG)\n",
    "    else:\n",
    "        fd = feature.hog(image, orientations=8, pixels_per_cell=(16, 16),\n",
    "                         cells_per_block=(1, 1), visualise=showHOG)\n",
    "    if(showHOG):\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), sharex=True, sharey=True)\n",
    "        ax1.axis('off')\n",
    "        ax1.imshow(image, cmap=plt.cm.gray)\n",
    "        ax1.set_title('Input image')\n",
    "        ax1.set_adjustable('box-forced')\n",
    "        # Rescale histogram for better display\n",
    "        hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 0.02))\n",
    "        ax2.axis('off')\n",
    "        ax2.imshow(hog_image_rescaled, cmap=plt.cm.gray)\n",
    "        ax2.set_title('Histogram of Oriented Gradients')\n",
    "        ax1.set_adjustable('box-forced')\n",
    "        plt.show()\n",
    "    return fd\n",
    "\n",
    "\n",
    "# Load a dataset (Data, Labels) from a folder.\n",
    "# Return data (HOGs, Class) and image list (as image file ames on disk)\n",
    "def load_dataset_from_folder(root_folder, rgb_folder, segmentation_folder):\n",
    "            \n",
    "    HOGs_list = []\n",
    "    Cs_list = []    \n",
    "    image_list = []\n",
    "    if os.path.exists(root_folder):\n",
    "        class_folders = next(os.walk(root_folder))[1]\n",
    "        class_folders.sort()\n",
    "        print(\"[INFO] Found \" + str(len(class_folders)) + \" class folders\")\n",
    "        print(class_folders)\n",
    "        sys.stdout.flush()\n",
    "        tot_classes = len(class_folders)\n",
    "        #used to resize the images\n",
    "        image_size = (128, 128)\n",
    "        class_list = range(tot_classes)\n",
    "        for class_folder,this_class in zip(class_folders,class_list):\n",
    "            print(\"\\n[INFO] Processing folder \" + class_folder)\n",
    "            sys.stdout.flush()\n",
    "            current_gesture_folder_rgb = root_folder + class_folder + \"/\" + rgb_folder + \"/*.jpg\"\n",
    "            current_gesture_folder_segmentation = root_folder + class_folder + \"/\" + segmentation_folder + \"/*.png\"\n",
    "            allfiles_imgs = glob.glob(current_gesture_folder_rgb)\n",
    "            allfiles_masks = glob.glob(current_gesture_folder_segmentation)\n",
    "            #for each image/mask pair\n",
    "            line_percentage_cnt = 0\n",
    "            for file_img,mask_img in zip(allfiles_imgs,allfiles_masks):\n",
    "                # Print completion percentage\n",
    "                sys.stdout.write('\\r')\n",
    "                progress_bar_msg = \"[%-100s] %d%% \" + str(line_percentage_cnt) + \"/\" + str(len(allfiles_imgs))\n",
    "                update_step = int( (float(100)/float(len(allfiles_imgs))) * float(line_percentage_cnt) )\n",
    "                sys.stdout.write(progress_bar_msg % ('='*update_step, update_step))\n",
    "                sys.stdout.flush()\n",
    "                img = io.imread(file_img)\n",
    "                mask = io.imread(mask_img)\n",
    "                mask = 255 - mask\n",
    "                img *= mask\n",
    "                # you can see the segmented image using:\n",
    "                #io.imshow(img)\n",
    "                #io.show()\n",
    "                \n",
    "                feat = extractHOG(transform.resize(img, image_size))\n",
    "                HOGs_list.append(feat)\n",
    "                Cs_list.append(this_class)\n",
    "                image_list.append(file_img)\n",
    "                line_percentage_cnt += 1\n",
    "        print(\"[INFO] Loaded data in. Number of samples: \"+ str(len(image_list)))\n",
    "    else:\n",
    "        print(\"[ERROR] Folder \" + root_folder + \" does not exist!\")\n",
    "        print(\"[ERROR] Have you run the setup cell?\")\n",
    "        sys.stdout.flush()\n",
    "        exit()\n",
    "        \n",
    "\n",
    "    HOGs = np.array(HOGs_list)\n",
    "    Cs = np.array(Cs_list)\n",
    "    return HOGs, Cs, image_list\n",
    "\n",
    "\n",
    "        \n",
    "# Class to store parameters of an SVM\n",
    "class SVMparameters:\n",
    "\n",
    "    def __init__(self, k='rbf', c='1', g='0.1', d=1):\n",
    "        self.kernel = k\n",
    "        self.C = c\n",
    "        self.gamma=g\n",
    "        self.degree = g\n",
    "\n",
    "    def setkernel(self, k):\n",
    "        self.kernel = k\n",
    "\n",
    "    def setgamma(self, g):\n",
    "        self.gamma = g\n",
    "\n",
    "    def setc(self, c):\n",
    "        self.C = c\n",
    "\n",
    "    def setdegree(self,d):\n",
    "        self.degree = d\n",
    "    \n",
    "    def printconfig(self):\n",
    "        print(\"Kernel: \" + self.kernel)\n",
    "        if self.kernel is \"poly\":\n",
    "            print(\"Degree: \" + str(self.degree))\n",
    "        print(\"C: \" + str(self.C))\n",
    "        print(\"Gamma: \" + str(self.gamma))\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-7aece435eef7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_folders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KDEF/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrain_folders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] Found \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" class folders\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_folders = next(os.walk(\"KDEF/\"))[1]\n",
    "train_folders.sort()\n",
    "print(\"[INFO] Found \" + str(len(train_folders)) + \" class folders\")\n",
    "sys.stdout.flush()\n",
    "\n",
    "\n",
    "image_list = []\n",
    "HOGs_list = []\n",
    "Cs_list = [] \n",
    "\n",
    "image_size = (128, 128)\n",
    "                \n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('FaceDetect/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('FaceDetect/haarcascade_eye.xml')\n",
    "\n",
    "emotion_list = ['AFS.JPG', 'ANS.JPG', 'DIS.JPG', 'HAS.JPG', 'NES.JPG', 'SAS.JPG', 'SUS.JPG']\n",
    "\n",
    "emotion_num = [0,1,2,3,4,5,6]\n",
    "\n",
    "ffile = []\n",
    "line_percentage_cnt = 0\n",
    "\n",
    "for class_folder,this_class in zip(train_folders,class_list):\n",
    "#     print(\"\\n[INFO] Processing folder \" + class_folder)\n",
    "    sys.stdout.flush()\n",
    "  \n",
    "    \n",
    "    ffile = os.listdir('KDEF/' + class_folder)\n",
    "\n",
    "    for i in ffile:\n",
    "        \n",
    "        for j in range(len(emotion_list)):\n",
    "\n",
    "            if i.endswith(emotion_list[j]): #afraid\n",
    "                \n",
    "                Cs_list.append(emotion_num[j])\n",
    "            \n",
    "                \n",
    "                directory = 'KDEF/train/' + emotion_list[j][0:3] \n",
    "                \n",
    "                RGB_subdir = 'RGB/'\n",
    "                segmented_subdir = 'segmented/'\n",
    "                \n",
    "                if not os.path.exists(directory):\n",
    "                    os.makedirs(directory)\n",
    "                     \n",
    "                if not os.path.exists(directory + \"/\" + RGB_subdir):\n",
    "                    os.makedirs(directory + \"/\" + RGB_subdir)\n",
    "                \n",
    "              \n",
    "                tmp_img = io.imread(\"KDEF/\" + class_folder + \"/\" + i)\n",
    "\n",
    "                \n",
    "            \n",
    "#                 sys.stdout.write('\\r')\n",
    "#                 progress_bar_msg = \"[%-100s] %d%% \" + str(line_percentage_cnt) + \"/\" + str(len(class_folder))\n",
    "#                 update_step = int( (float(100)/float(len(allfiles_imgs))) * float(line_percentage_cnt) )\n",
    "#                 sys.stdout.write(progress_bar_msg % ('='*update_step, update_step))\n",
    "#                 sys.stdout.flush()\n",
    "\n",
    "#                 feat = extractHOG(img_resize)\n",
    "        \n",
    "#                 HOGs_list.append(feat)\n",
    "    #             Cs_list.append(this_class)\n",
    "#                 image_list.append(tmp_img)\n",
    "\n",
    "#                 img = cv2.imread(\"KDEF/AF01/AF01AFFL.JPG\")\n",
    "                gray = cv2.cvtColor(tmp_img,cv2.COLOR_BGR2GRAY)\n",
    "                ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "        \n",
    "        \n",
    "                ###########################\n",
    "   \n",
    "                faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "                for (x,y,w,h) in faces:\n",
    "                    cv2.rectangle(tmp_img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "                    roi_gray = gray[y:y+h, x:x+w]\n",
    "                    roi_color = tmp_img[y:y+h, x:x+w]\n",
    "                    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#                     mouth = mouth_cascade.detectMultiScale(roi_gray)\n",
    "                    for (ex,ey,ew,eh) in eyes:\n",
    "                        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "                img_resize = tmp_img[y:y+h,x:x+w]\n",
    "\n",
    "                \n",
    "                io.imsave(directory + \"/\" + RGB_subdir + i, img_resize)\n",
    "                \n",
    "                ##########################\n",
    "\n",
    "# #                 # noise removal\n",
    "#                 kernel = np.ones((3,3),np.uint8)\n",
    "#                 opening = cv2.morphologyEx(thresh,cv2.MORPH_OPEN,kernel, iterations = 2)\n",
    "\n",
    "# #                 # sure background area\n",
    "#                 sure_bg = cv2.dilate(opening,kernel,iterations=3)\n",
    "\n",
    "# #                 # Finding sure foreground area\n",
    "#                 dist_transform = cv2.distanceTransform(opening,cv2.DIST_L2,5)\n",
    "#                 ret, sure_fg = cv2.threshold(dist_transform,0.7*dist_transform.max(),255,0)\n",
    "\n",
    "# #                 # Finding unknown region\n",
    "#                 sure_fg = np.uint8(sure_fg)\n",
    "#                 mask_img = cv2.subtract(sure_bg,sure_fg)\n",
    "\n",
    "#                 if not os.path.exists(directory + \"/\" + segmented_subdir):\n",
    "#                     os.makedirs(directory + \"/\" + segmented_subdir)\n",
    "                    \n",
    "# #               #  cv2.imwrite('KDEF/test.png', mask_img)\n",
    "#                 io.imsave(directory + \"/\" + segmented_subdir + i, mask_img)\n",
    "\n",
    "#                 mask = 255 - mask_img\n",
    "#                 gray *= mask \n",
    "                feat = extractHOG(transform.resize(gray, image_size))\n",
    "\n",
    "                HOGs_list.append(feat)\n",
    "#                 Cs_list.append(this_class)\n",
    "                image_list.append(img_resize)\n",
    "                \n",
    "\n",
    "        \n",
    "HOGs = np.array(HOGs_list)\n",
    "Cs = np.array(Cs_list)\n",
    "\n",
    "    \n",
    "#     return HOGs, Cs, image_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27,)\n",
      "(26, 512)\n",
      "[[ 0.14609814  0.12117097  0.14287373 ...,  0.14274769  0.13119912\n",
      "   0.15155299]\n",
      " [ 0.13584005  0.10375794  0.09584122 ...,  0.10469337  0.29519536\n",
      "   0.20800742]\n",
      " [ 0.11525013  0.13461331  0.14456521 ...,  0.09289259  0.13120285\n",
      "   0.13091405]\n",
      " ..., \n",
      " [ 0.13793544  0.11253077  0.0739627  ...,  0.23146913  0.08510341\n",
      "   0.03691273]\n",
      " [ 0.15407291  0.0795464   0.10900269 ...,  0.13396517  0.08840256\n",
      "   0.08799493]\n",
      " [ 0.15178736  0.10734501  0.11620615 ...,  0.12332238  0.04529716\n",
      "   0.02370515]]\n",
      "[0 1 2 3 4 5 6 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "HOGs = np.array(HOGs_list)\n",
    "Cs = np.array(Cs_list)\n",
    "\n",
    "print Cs.shape\n",
    "print HOGs.shape\n",
    "\n",
    "print HOGs[0:10]\n",
    "print Cs[0:10]\n",
    "# print image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******\n",
      "Number of folds: 1\n",
      "Train-set size: 98\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.122448979592(12/98)\n",
      "Precision: 0.0174927113703\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0 15  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0]\n",
      " [ 0  8  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0]\n",
      " [ 0 14  0  0  0  0  0]\n",
      " [ 0 16  0  0  0  0  0]]\n",
      "******\n",
      "******\n",
      "Number of folds: 2\n",
      "Train-set size: 196\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.19387755102(19/98)\n",
      "Precision: 0.0578231292517\n",
      "Recall: 0.193452380952\n",
      "Confusion Matrix\n",
      "[[ 0  7  0  0  0  0  8]\n",
      " [ 0  8  0  0  0  0  4]\n",
      " [ 0 19  0  0  0  0  2]\n",
      " [ 0  5  0  0  0  0  3]\n",
      " [ 0  4  0  0  0  0  8]\n",
      " [ 0  8  0  0  0  0  6]\n",
      " [ 0  5  0  0  0  0 11]]\n",
      "******\n",
      "******\n",
      "Number of folds: 3\n",
      "Train-set size: 294\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.163265306122(16/98)\n",
      "Precision: 0.0233236151603\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0  0  0  0 15]\n",
      " [ 0  0  0  0  0  0 12]\n",
      " [ 0  0  0  0  0  0 21]\n",
      " [ 0  0  0  0  0  0  8]\n",
      " [ 0  0  0  0  0  0 12]\n",
      " [ 0  0  0  0  0  0 14]\n",
      " [ 0  0  0  0  0  0 16]]\n",
      "******\n",
      "******\n",
      "Number of folds: 4\n",
      "Train-set size: 392\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.163265306122(16/98)\n",
      "Precision: 0.0233236151603\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0  0  0  0 15]\n",
      " [ 0  0  0  0  0  0 12]\n",
      " [ 0  0  0  0  0  0 21]\n",
      " [ 0  0  0  0  0  0  8]\n",
      " [ 0  0  0  0  0  0 12]\n",
      " [ 0  0  0  0  0  0 14]\n",
      " [ 0  0  0  0  0  0 16]]\n",
      "******\n",
      "******\n",
      "Number of folds: 5\n",
      "Train-set size: 490\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.122448979592(11/98)\n",
      "Precision: 0.0174927113703\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0  0 15  0  0]\n",
      " [ 0  0  0  0 12  0  0]\n",
      " [ 0  0  0  0 21  0  0]\n",
      " [ 0  0  0  0  8  0  0]\n",
      " [ 0  0  0  0 12  0  0]\n",
      " [ 0  0  0  0 14  0  0]\n",
      " [ 0  0  0  0 16  0  0]]\n",
      "******\n",
      "******\n",
      "Number of folds: 6\n",
      "Train-set size: 588\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.0816326530612(8/98)\n",
      "Precision: 0.0116618075802\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 15  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 21  0  0  0]\n",
      " [ 0  0  0  8  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 14  0  0  0]\n",
      " [ 0  0  0 16  0  0  0]]\n",
      "******\n",
      "******\n",
      "Number of folds: 7\n",
      "Train-set size: 686\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.0816326530612(8/98)\n",
      "Precision: 0.0116618075802\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 15  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 21  0  0  0]\n",
      " [ 0  0  0  8  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 14  0  0  0]\n",
      " [ 0  0  0 16  0  0  0]]\n",
      "******\n",
      "******\n",
      "Number of folds: 8\n",
      "Train-set size: 784\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.0816326530612(8/98)\n",
      "Precision: 0.0116618075802\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 15  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 21  0  0  0]\n",
      " [ 0  0  0  8  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 14  0  0  0]\n",
      " [ 0  0  0 16  0  0  0]]\n",
      "******\n",
      "******\n",
      "Number of folds: 9\n",
      "Train-set size: 882\n",
      "Test-set size: 98\n",
      "(RW) Accuracy: 0.0816326530612(8/98)\n",
      "Precision: 0.0116618075802\n",
      "Recall: 0.142857142857\n",
      "Confusion Matrix\n",
      "[[ 0  0  0 15  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 21  0  0  0]\n",
      " [ 0  0  0  8  0  0  0]\n",
      " [ 0  0  0 12  0  0  0]\n",
      " [ 0  0  0 14  0  0  0]\n",
      " [ 0  0  0 16  0  0  0]]\n",
      "******\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import pickle\n",
    "\n",
    "\n",
    "    \n",
    "# Split the data in K-fold\n",
    "num_of_folds = 5\n",
    "test_ratio = 1.0 / float(num_of_folds) #reserve one for testing\n",
    "HOGs_train, HOGs_test, Cs_train, Cs_test = train_test_split(HOGs, Cs, test_size=test_ratio, random_state=42)\n",
    "fold_size = HOGs.shape[0]/num_of_folds #size of individual fold\n",
    "\n",
    "\n",
    "\n",
    "all_acc = []\n",
    "all_prec = []\n",
    "all_rec = []\n",
    "clf_pt1 = svm.SVC(decision_function_shape='ova') # ovo = one-vs-one, for all classes\n",
    "\n",
    "#grow the training set adding a fold each time, then test the perfomances\n",
    "for i in range(1, num_of_folds):\n",
    "\n",
    "    print(\"******\")\n",
    "    print(\"Number of folds: \" + str(i))\n",
    "    sys.stdout.flush()\n",
    "\n",
    "    ## TRAINING ##\n",
    "\n",
    "    #build training set\n",
    "    HOGs_growing_train = HOGs_train[0:(i*fold_size),:]\n",
    "    Cs_growing_train = Cs_train[0:(i*fold_size)]\n",
    "        \n",
    "    print(\"Train-set size: \" + str(len(Cs_growing_train)))\n",
    "    print(\"Test-set size: \" + str(len(Cs_test)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    #train multi-class SVM\n",
    "    clf_pt1 = svm.SVC(decision_function_shape='ova')\n",
    "    clf_pt1.fit(HOGs_growing_train, Cs_growing_train.ravel())\n",
    "\n",
    "    ## TESTING ##\n",
    "\n",
    "    # test\n",
    "    Cs_predicted = clf_pt1.predict(HOGs_test)\n",
    "\n",
    "    # compute stats    \n",
    "    accuracy, precision, recall = compute_scores(Cs_predicted, Cs_test, verbose=True)\n",
    "    all_acc.append(accuracy)\n",
    "    all_prec.append(precision)\n",
    "    all_rec.append(recall)\n",
    "\n",
    "    print(\"******\")\n",
    "    sys.stdout.flush()\n",
    "\n",
    "# now plot\n",
    "x = range(1, num_of_folds)\n",
    "fig = plt.figure()\n",
    "fig.suptitle(\"Performances\")\n",
    "\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax1.plot(x, all_acc)\n",
    "ax1.locator_params(nbins=num_of_folds-1)\n",
    "\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.set_title(\"Precision\")\n",
    "ax2.plot(x, all_prec)\n",
    "ax2.locator_params(nbins=num_of_folds-1)\n",
    "\n",
    "ax3 = fig.add_subplot(313)\n",
    "ax3.set_title(\"Recall\")\n",
    "ax3.plot(x, all_rec)\n",
    "ax3.locator_params(nbins=num_of_folds-1)\n",
    "\n",
    "#minimise subplots overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 379, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "face_cascade = cv2.CascadeClassifier('FaceDetect/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('FaceDetect/haarcascade_eye.xml')\n",
    "# mouth_cascade = cv2.CascadeClassifier('FaceDetect/haarcascade_smile.xml')\n",
    "\n",
    "\n",
    "img = cv2.imread('KDEF/AF01/AF01AFS.JPG')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "#     mouth = mouth_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey,ew,eh) in eyes:\n",
    "        cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "    \n",
    "#     for (ex,ey,ew,eh) in mouth:\n",
    "#         cv2.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
    "\n",
    "height, width = img.shape[:2]\n",
    "        \n",
    "img_resize = img[y:y+h,x:x+w]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = io.imread(\"KDEF/AF01/AF01AFFL.JPG\")\n",
    "mask = io.imread(mask_img\n",
    "mask = 255 - mask\n",
    "img *= mask\n",
    "# you can see the segmented image using:\n",
    "#io.imshow(img)\n",
    "#io.show()\n",
    "feat = extractHOG(transform.resize(img, image_size))\n",
    "\n",
    "extractHOG(img, showHOG=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
